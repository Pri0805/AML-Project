{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9123ca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping umap as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: umap-learn in /Users/angky/anaconda3/lib/python3.11/site-packages (0.5.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/angky/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /Users/angky/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /Users/angky/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.3.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in /Users/angky/anaconda3/lib/python3.11/site-packages (from umap-learn) (0.57.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Users/angky/anaconda3/lib/python3.11/site-packages (from umap-learn) (0.5.11)\n",
      "Requirement already satisfied: tqdm in /Users/angky/anaconda3/lib/python3.11/site-packages (from umap-learn) (4.65.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/angky/anaconda3/lib/python3.11/site-packages (from numba>=0.51.2->umap-learn) (0.40.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/angky/anaconda3/lib/python3.11/site-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/angky/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "# installing libraries\n",
    "!pip uninstall umap --yes\n",
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16761adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# import umap\n",
    "import umap.umap_ as umap\n",
    "from collections import defaultdict\n",
    "\n",
    "from scipy import linalg, spatial\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, SparsePCA, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, TfidfTransformer, TfidfVectorizer)\n",
    "\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12358a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     title                                        description  \\\n",
      "0  The Old Man and the Sea  Librarian's note: An alternate cover edition c...   \n",
      "1       The Vampire Lestat  Lestat. The vampire hero of Anne Rice's enthra...   \n",
      "2     The Poisonwood Bible  The Poisonwood Bible is a story told by the wi...   \n",
      "3        Different Seasons  Includes the stories “The Body” and “Rita Hayw...   \n",
      "4            Invisible Man  First published in 1952 and immediately hailed...   \n",
      "5            Battle Royale  Koushun Takami's notorious high-octane thrille...   \n",
      "6    I'll Give You the Sun  At first, Jude and her twin brother Noah, are ...   \n",
      "7    Because of Winn-Dixie  The summer Opal and her father, the preacher, ...   \n",
      "8            Lover Avenged  Rehvenge has always kept his distance from the...   \n",
      "9                Ficciones  The seventeen pieces in Ficciones demonstrate ...   \n",
      "\n",
      "                               processed_description  cluster  \n",
      "0  librarian note alternate cover edition found h...        3  \n",
      "1  lestat vampire hero anne rice enthralling new ...        1  \n",
      "2  poisonwood bible story told wife four daughter...        0  \n",
      "3  includes story body rita hayworth shawshank re...        0  \n",
      "4  first published immediately hailed masterpiece...        3  \n",
      "5  koushun takami notorious high octane thriller ...        0  \n",
      "6  first jude twin brother noah inseparable noah ...        5  \n",
      "7  summer opal father preacher move naomi florida...        9  \n",
      "8  rehvenge always kept distance brotherhood even...        9  \n",
      "9  seventeen piece ficciones demonstrate whirlwin...        3  \n"
     ]
    }
   ],
   "source": [
    "filename =  '/Users/angky/Cornell/AML/AMLProjectTemp/AML-Project/clustered_books.csv'\n",
    "df = pd.read_csv(filename)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24026a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_description'] = df['processed_description'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac91aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training, development = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f44a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Your existing setup\n",
    "vectorizer = CountVectorizer(binary=True, min_df=2)\n",
    "training_text = training['processed_description']\n",
    "\n",
    "# Fit the vectorizer to the training data and transform the training data\n",
    "X_train_bow = vectorizer.fit_transform(training_text)\n",
    "\n",
    "# Extract the feature names (unique words)\n",
    "unique_words_training = set(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e84f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing setup\n",
    "vectorizer = CountVectorizer(binary=True, min_df=2)\n",
    "development_text = development['processed_description']\n",
    "\n",
    "# Fit the vectorizer to the training data and transform the training data\n",
    "X_development_bow = vectorizer.fit_transform(development_text)\n",
    "\n",
    "# Extract the feature names (unique words)\n",
    "unique_words_development = set(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fefe669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = unique_words_training.intersection(unique_words_development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27893a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in training set: 21605\n",
      "Unique words in development set: 13630\n",
      "Number of common words: 12076\n"
     ]
    }
   ],
   "source": [
    "print(f'Unique words in training set: {len(unique_words_training)}')\n",
    "print(f'Unique words in development set: {len(unique_words_development)}')\n",
    "print(f'Number of common words: {len(intersection)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc0ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
